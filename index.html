<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Stefanos Gkikas</title>

    <meta name="author" content="Stefanos Gkikas">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/icons/moomin_2.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Stefanos Gkikas
                </p>
                <p>I am a Ph.D. candidate focusing on <strong>Affective Computing</strong> and  <strong>Emotion AI</strong>. My doctoral research 
			specifically focuses on <strong> automatic pain assessment</strong> using multimodal data sources. 
			Currently, I am collaborating with the <a href="https://bmi.hmu.gr/">Biomedical Informatics & eHealth  Laboratory</a> 
			of the Hellenic Mediterranean University 
			and with the <a href="https://www.ics.forth.gr/cbml/about-cbml">Computational BioMedicine Laboratory (CBML)</a>, 
			part of the Institute of Computer Science at FORTH</a>.
                </p>
                <p>
                  I am interested in <strong>emotion recognition</strong> and <strong>human behavior analysis</strong>, employing 
			advanced deep-learning methods for video data and biosignals</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:gikasstefanos@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/stef.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=Pm1tx9oAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/GkikasStefanos/">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/icons/profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/icons/profile.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
	  </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



<tr onmouseout="alignerf_stop()" onmouseover="alignerf_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='twins'>
              <img src='images/attention.png' width="160" height="130"></div>
            <img src='images/full.png' width="160">
          </div>
          <script type="text/javascript">
            function alignerf_start() {
              document.getElementById('twins').style.opacity = "1";
            }

            function alignerf_stop() {
              document.getElementById('twins').style.opacity = "0";
            }
            alignerf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://y">
            <span class="papertitle">Twins-PainViT: Towards a Modality-Agnostic Vision Transformer Framework for Multimodal Automatic Pain Assessment 
		    using Facial Videos and fNIRS</span>
          </a>
          <br>
           <strong>Stefanos Gkikas</strong>,
           Manolis Tsiknakis
	    <br>
	    <em>12th International Conference on Affective Computing & Intelligent Interaction </em>, 2023
	    <br>
	     <span style="color: #DE3163;">Accepted-Pending Publication</span>
	    <br>
	    <a href="https://github.io/" style="color:#0a7e6a;">github</a>
		          /
	        <a href="https://arxiv.org" style="color:#0a7e6a;">arXiv</a>
		
	    <p> The proposed multimodal framework utilizes facial videos and fNIRS and presents a modality-agnostic approach, alleviating the need for 
		    domain-specific models. Employing a dual ViT configuration and adopting waveform representations for the fNIRS, as well as for 
		    the extracted embeddings from the two modalities, demonstrate the efficacy of the proposed method.</p>
	  </td>
	</tr>




	

		  

<tr onmouseout="synthetic_stop()" onmouseover="synthetic_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='synthetic'>
              <img src='images/faces.png' width="160" height="90"></div>
            <img src='images/mlp.png' width="160">
          </div>
          <script type="text/javascript">
            function synthetic_start() {
              document.getElementById('synthetic').style.opacity = "1";
            }

            function synthetic_stop() {
              document.getElementById('synthetic').style.opacity = "0";
            }
            alignerf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://y">
            <span class="papertitle">Synthetic Thermal and RGB Videos for Automatic Pain Assessment utilizing a Vision-MLP Architecture</span>
          </a>
          <br>
           <strong>Stefanos Gkikas</strong>,
           Manolis Tsiknakis
	    <br>
	    <em>12th International Conference on Affective Computing & Intelligent Interaction </em>, 2023
	    <br>
          <span style="color: #DE3163;">Accepted-Pending Publication</span>
	    <br>
	    <a href="https://github.io/" style="color:#0a7e6a;">github</a>
		          /
	        <a href="http://arxiv.org" style="color:#0a7e6a;">arXiv</a>
	    <p> This study presents synthetic thermal videos generated by Generative Adversarial Networks integrated into the pain recognition pipeline 
		    and evaluates their efficacy. A framework consisting of a Vision-MLP and a Transformer-based module is utilized, employing RGB and 
		    synthetic thermal videos in unimodal and multimodal settings.</p>
	  </td>
	</tr>
		  



		  
		  
<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='5_paper'>
        <img src='images/transformer_2.png' width="100%" alt="MTL">
      </div>
    </div>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://www.frontiersin.org/journals/pain-research/articles/10.3389/fpain.2024.1372814/full">
      <span class="papertitle">Multimodal automatic assessment of acute pain through facial videos and heart rate signals utilizing transformer-based architectures</span>
    </a>
    <br>
    <strong>Stefanos Gkikas</strong>,
    Nikolaos S. Tachos, Stelios Andreadis, Vasileios C. Pezoulas, Dimitrios Zaridis, George Gkois,
    Anastasia Matonaki, Thanos G. Stavropoulos, Dimitrios I. Fotiadis
    
	  
    <br>
    <em>Frontiers in Pain Research</em>, 2023
    <br>
    <a href="https://github.io/" style="color:#0a7e6a;">github</a>
    <p> The proposed framework comprises four pivotal modules: the Spatial Module, responsible for extracting embeddings from videos; the Heart Rate Encoder, 
	    tasked with mapping heart rate signals into a higher dimensional space; the AugmNet, designed to create learning-based augmentations 
	    in the latent space; and the Temporal Module, which utilizes the extracted video and heart rate embeddings for the final assessment.</p>
  </td>
</tr>




		  
<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='4_paper'>
        <img src='images/transformer_1.png' width="100%" alt="MTL">
      </div>
    </div>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://ieeexplore.ieee.org/abstract/document/10340872">
      <span class="papertitle">A Full Transformer-based Framework for Automatic Pain Estimation using Videos</span>
    </a>
    <br>
    <strong>Stefanos Gkikas</strong>,
    Manolis Tsiknakis
    <br>
    <em>45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)</em>, 2023
    <br>
    <a href="https://github.io/" style="color:#0a7e6a;">github</a>
    <p> Presenting a full transformer-based framework consisting of a  Transformer in Transformer (TNT) model and a 1D Transformer leveraging cross-attention and self-attention blocks for video analysis.</p>
  </td>
</tr>



		  



<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='3_paper'>
        <img src='images/mtl.png' width="100%" alt="MTL">
      </div>
    </div>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://link.springer.com/chapter/10.1007/978-3-031-37496-8_17">
      <span class="papertitle">Multi-task Neural Networks for Pain Intensity Estimation Using Electrocardiogram and Demographic Factors</span>
    </a>
    <br>
    <strong>Stefanos Gkikas</strong>,
    Chariklia Chatzaki,
    Manolis Tsiknakis
    <br>
    <em>Information and Communication Technologies for Ageing Well and e-Health, Communications in Computer and Information Science</em>, 2023
    <br>
    <a href="https://github.io/" style="color:#0a7e6a;">github</a>
    <p> Introduction of a novel multi-task neural network for automatic pain assessment utilizing the age and gender information of each individual alongside the pain estimation.</p>
  </td>
</tr>

		  


		  
<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='2_paper'>
        <img src='images/slr.png' width="100%" alt="SLR">
      </div>
    </div>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://www.sciencedirect.com/science/article/pii/S0169260723000329">
      <span class="papertitle">Automatic assessment of pain based on deep learning methods: A systematic review</span>
    </a>
    <br>
    <strong>Stefanos Gkikas</strong>,
    Manolis Tsiknakis
    <br>
    <em>Computer Methods and Programs in Biomedicine</em>, 2023
    <br>
    <p> This review aims to identify original studies based on deep learning approaches and discuss the models, the methods, and the types of data employed in establishing the 
	foundation of a deep learning-based automatic pain assessment system.</p>
  </td>
</tr>





		  
<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='1_paper'>
        <img src='images/pan_tompkins.png' width="100%" alt="Pan Tompkins Algorithm Output">
      </div>
    </div>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://www.scitepress.org/PublishedPapers/2022/109717/109717.pdf">
      <span class="papertitle">Automatic Pain Intensity Estimation based on Electrocardiogram and Demographic Factors</span>
    </a>
    <br>
    <strong>Stefanos Gkikas</strong>,
    Chariklia Chatzaki,
    Elisavet Pavlidou,
    Foteini Verigou,
    Kyriakos Kalkanis,
    Manolis Tsiknakis
    <br>
    <em>8th International Conference on Information and Communication Technologies for Ageing Well and e-Health</em>, 2022
    <br>
    <a href="https://github.io/" style="color:#0a7e6a;">github</a>
    <p>Extracting hand-crafted features from electrocardiography signals with machine learning algorithms and exploring the correlation
	    of gender and age with the manifestation of pain.</p>
  </td>
</tr>



      

      
  


            
            

